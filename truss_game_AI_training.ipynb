{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Truss game AI training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+gPtuaItE5ms6o5xoHgvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkrauter/TrussGame/blob/master/truss_game_AI_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMlSKzIL_gJb"
      },
      "source": [
        "\n",
        "# Neural network training for the Truss game\n",
        "\n",
        "This is the Google Colab notebook for training the convolutional neural network model to be used in the Truss game.\n",
        "\n",
        "Read more about the idea at ['Is a fruit fly a smarter engineer than you?'](https://marton-krauter.medium.com/is-a-fruit-fly-a-smarter-engineer-than-you-850db1031fe8)\n",
        "\n",
        "\n",
        "## Setting up the environment\n",
        "\n",
        "Let's import the necessary modules and check if the virtual machine is working fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlXXeRBdm9kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a4a612-e04e-4331-d0d9-2bd964045942"
      },
      "source": [
        "import os, datetime\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.spatial\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "print(\"Num GPUs available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs available: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXDN2w3spjRd"
      },
      "source": [
        "You should see 'Num GPUs available: 1', indicating the the virtual machine is set up and running correctly.\n",
        "\n",
        "Next we install and import the Pygame package and configure it to run without a display."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIL8wCk1fSD7",
        "outputId": "604e5340-7394-42f2-90a7-9ae5f9ef305c"
      },
      "source": [
        "!pip install pygame\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "import pygame"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "  Downloading pygame-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 14.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.0.1\n",
            "pygame 2.0.1 (SDL 2.0.14, Python 3.7.11)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtgcVK-PtT7D"
      },
      "source": [
        "# Preparing the training dataset\n",
        "\n",
        "In order to train our neural network first we need to provide significant number of sample data (input-output pairs) to let the model learn from.\n",
        "\n",
        "Two tasks needed to be done\n",
        "\n",
        "1.   Create sample data and make it available for our virtual machine\n",
        "2.   Convert sample data into a consumable format\n",
        "\n",
        "##Data feed methods\n",
        "\n",
        "Creating sample images from the game itself on your local computer is really a trivial task, Pygame has functions to capture any region of the window at any time. We may write a iterative function to create a random truss, save the screen as an image, solve the truss system to get the displacement and write the result coordinates to a text file.\n",
        "\n",
        "Making the images available to our virtual (training) machine is where things start to get a bit complicated. First, you will need to upload the images to a folder in your Google Drive (for 2000 images this will definitely take some time), then you can mount your Google Drive here in the virtual machine to gain access to data for further processing.\n",
        "\n",
        "We may optimize this process slightly by instead of saving images putting them into a Numpy array. Numpy has a functionality to save data structures to a file (think of how Pickle works), it even compresses them thus we need to transfer only one file, speeding up the process significantlty.\n",
        "\n",
        "There is another problem with this approach. By their nature Numpy arrays need to fit entirely into the memory (here the memory of the virtual machine). This puts a hard limit on choosing the size of the training set, over 2000 samples you most probably will run out of memory.\n",
        "\n",
        "We have a solution for both issues:\n",
        "1.  We may utilize that our game (thus the training data) is purely synthetic. We can generate any number of samples in just a matter of seconds, so doing it _in situ_, in our Colab virtual machine sounds like a good plan, we don't need to transfer any data then.\n",
        "2.  Tensorflow, the machine learning framework running behind Colab has its own optimized data structure ```tfrecord``` for storing training data. It is definitely not the easiest thing to understand at first, but using it avoids memory issues and it also has functions you may find useful later in your journey.\n",
        "\n",
        "For the sake of simplicity we use Numpy way of feeding, but later I will update this part with the proper TFrecord method.\n",
        "\n",
        "Enough talking, let's roll up our sleeves...\n",
        "\n",
        "#Generate our data\n",
        "\n",
        "The following code block is a simplified copy of the classes from ```truss_game_AI.py``` from the repo. Having copies of the codebase can quickly lead to problems, but I wanted to keep the code fully modifiable. Long story short, if you modify your local version, please make sure to keep this one in sync.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L16GGfc1dZb7"
      },
      "source": [
        "class TrussGameAI:\n",
        "    def __init__(self, window_size=(900, 900), force=100000):\n",
        "        pygame.init()\n",
        "        pygame.display.init()\n",
        "        self.screen = pygame.display.set_mode(window_size)\n",
        "        self.clock = pygame.time.Clock()\n",
        "        self.force = force\n",
        "\n",
        "    def __draw_truss(self):\n",
        "        self.__draw_triangle(pos=self.truss.nodes[self.truss.supports], color=(64, 128, 64))\n",
        "        self.__draw_triangle(pos=self.truss.nodes_moved[self.truss.loaded_node], color=(100, 100, 200), up=False)\n",
        "        for i, e in enumerate(self.truss.elements):\n",
        "            pygame.draw.aaline(self.screen, self.__stress_color(self.truss.sigmas[i]),\n",
        "                               self.truss.nodes_moved[e[0]], self.truss.nodes_moved[e[1]])\n",
        "\n",
        "    def __draw_triangle(self, pos, color, up=True, size=(10, 20)):\n",
        "        direction = 1 if up else -1\n",
        "        [pygame.draw.polygon(self.screen, color, [p,\n",
        "                                                  (p[0] - size[0], p[1] + size[1]*direction),\n",
        "                                                  (p[0] + size[0], p[1] + size[1]*direction)]) for p in pos]\n",
        "\n",
        "    @staticmethod\n",
        "    def __stress_color(sigma, scale=3):\n",
        "        return (int(max(min(-sigma*scale + 255, 255), 0)),\n",
        "                int(max(min(255 - abs(sigma*scale), 255), 0)),\n",
        "                int(max(min(sigma*scale + 255, 255), 0)))\n",
        "\n",
        "\n",
        "    def save_training_set(self, count, region=(68, 68, 768, 768)):\n",
        "        images = []\n",
        "        coords = []\n",
        "        coords_start = []\n",
        "        for i in range(count):\n",
        "            self.truss = Truss()\n",
        "            self.screen.fill(pygame.Color('grey25'))\n",
        "            self.__draw_truss()\n",
        "            self.truss.calculate(self.force)\n",
        "            images.append(pygame.surfarray.array3d(self.screen.subsurface(region)).swapaxes(0,1))\n",
        "            coords.append(self.truss.nodes_moved[self.truss.loaded_node][0])\n",
        "            coords_start.append(self.truss.nodes[self.truss.loaded_node][0])\n",
        "        images, coords, coords_start = np.asarray(images), np.asarray(coords), np.asarray(coords_start)\n",
        "        np.savez_compressed('Truss_training_dataset', images=images, coords=coords, coords_start=coords_start)\n",
        "\n",
        "\n",
        "class Truss:\n",
        "    def __init__(self, size=(700, 500), num_nodes=10, min_distance=100, offset=100):\n",
        "        points = []\n",
        "        while len(points) < num_nodes:\n",
        "            point = size * np.random.rand(2) + offset\n",
        "            for p in points:\n",
        "                if np.linalg.norm(point-p) < min_distance: break\n",
        "            else: points.append(point)\n",
        "        triangles = scipy.spatial.Delaunay(points)\n",
        "        self.nodes = triangles.points\n",
        "        self.elements = np.unique([sorted([s[i], s[(i+1) % 3]]) for s in triangles.simplices for i in range(3)], axis=0)\n",
        "        self.supports = [np.argmin(self.nodes[:, 0]), np.argmax(self.nodes[:, 0])]\n",
        "        moving_nodes = np.delete(np.arange(num_nodes), self.supports)\n",
        "        self.loaded_node = [np.random.choice(moving_nodes)]\n",
        "        self.moving_rows = np.sort(np.concatenate([moving_nodes*2, moving_nodes*2+1]))\n",
        "        self.sigmas = np.zeros([len(self.elements), 1])\n",
        "        self.nodes_moved = self.nodes\n",
        "\n",
        "    def calculate(self, force, E=200, A=1000):\n",
        "        vector_size = len(self.nodes)*2\n",
        "        K = np.zeros((vector_size, vector_size))\n",
        "        f = np.zeros((vector_size, 1))\n",
        "        u = np.zeros((vector_size, 1))\n",
        "        for loaded_node in self.loaded_node:\n",
        "            f[loaded_node * 2 + 1, 0] = force\n",
        "        for e in self.elements:\n",
        "            rows, length, c, s = self.__convert_global(e, nodes)\n",
        "            K[np.ix_(rows, rows)] += E*A/length * np.array([[c**2, c*s, -c**2, -c*s],\n",
        "                                                            [c*s, s**2, -c*s, -s**2],\n",
        "                                                            [-c**2, -c*s, c**2, c*s],\n",
        "                                                            [-c*s, -s**2, c*s, s**2]])\n",
        "        u[self.moving_rows] = np.linalg.solve(K[np.ix_(self.moving_rows, self.moving_rows)], f[self.moving_rows])\n",
        "        self.nodes_moved = self.nodes + np.reshape(u, (len(self.nodes), 2))\n",
        "        for i, e in enumerate(self.elements):\n",
        "            rows, length, c, s = self.__convert_global(e, nodes_moved)\n",
        "            d = np.dot([[c, s, 0, 0],\n",
        "                        [0, 0, c, s]], u[rows])\n",
        "            self.sigmas[i] = E * (d[1] - d[0]) / length\n",
        "\n",
        "    def __convert_global(self, e, nodes):\n",
        "        rows = [e[0]*2, e[0]*2+1, e[1]*2, e[1]*2+1]\n",
        "        dx, dy = (self.nodes[e[1], 0] - self.nodes[e[0], 0]), (nodes[e[1], 1] - nodes[e[0], 1])\n",
        "        length = np.linalg.norm((dx, dy))\n",
        "        c, s = dx/length, dy/length\n",
        "        return rows, length, c, s"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkzg4UzowvGo"
      },
      "source": [
        "Let's generate 2000 sample image-coordinate pairs and save it to the disk. This takes slightly more than a minute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZiXQgMdgaN-",
        "outputId": "f9b8a0e4-2d2d-466b-c94e-bb837fc33770"
      },
      "source": [
        "tg = TrussGameAI()\n",
        "tg.save_training_set(count=2000)\n",
        "del tg\n",
        "print('Training dataset created successfully.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset created successfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAbD4qXmd-MC"
      },
      "source": [
        "Load back the data, and separate the different data types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5YiiaVQqL5S",
        "outputId": "f3636e76-b212-4cee-c3db-30600eec1a6c"
      },
      "source": [
        "dataset = np.load('/content/Truss_training_dataset.npz')\n",
        "images = dataset['images']\n",
        "coords = dataset['coords']\n",
        "coords_start = dataset['coords_start']\n",
        "del dataset\n",
        "print(f'Images {images.shape} and coordinates {coords.shape} loaded successfully.')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images (2000, 768, 768, 3) and coordinates (2000, 2) loaded successfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxvDhomZhNbn"
      },
      "source": [
        "We preserve 20% of the training samples for validation. Validation helps revealing if our model has a tendency to 'overfit', which occurs if our model -- instead of learning information useful in general -- starts to learn information specific to the training data itself, thus to perform remarkably worse on 'never seen' samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuAuExlPvEJr",
        "outputId": "a9ce46c2-46d4-46ee-b21e-ebd83a51bf4c"
      },
      "source": [
        "validation_split = 0.2\n",
        "validation_count = int(validation_split * len(images))\n",
        "train_images, train_coords = images[validation_count:], coords[validation_count:]\n",
        "val_images, val_coords = images[:validation_count], coords[:validation_count]\n",
        "print(f'Training images {train_images.shape} and coordinates {train_coords.shape} allocated.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 768, 768, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNPBUXyO__wN"
      },
      "source": [
        "#Build the convolutional neural network\n",
        "\n",
        "Let's construct our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txX9vb52XlCH",
        "outputId": "364fdc26-8761-4a4f-b309-730135a07b15"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.Input(shape=(768, 768, 3)),\n",
        "  tf.keras.layers.experimental.preprocessing.Resizing(256, 256),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  # tf.keras.layers.Dropout(0.25),\n",
        "  tf.keras.layers.Dense(2, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=\"mse\", metrics=\"mae\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resizing (Resizing)          (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 252, 252, 32)      9248      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 250, 250, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 125, 125, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 123, 123, 32)      9248      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 121, 121, 32)      9248      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 119, 119, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 59, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 57, 57, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 55, 55, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 53, 53, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 22, 22, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 20, 20, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                204864    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 307,618\n",
            "Trainable params: 307,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aap1npojujeT"
      },
      "source": [
        "#Train the model\n",
        "\n",
        "We have all set, only executing the training left. We keep it running for 50 epochs (think of it as learning repetition cycle). Running it any longer will not improve performance, but will just introduce an ever increasing overfit.\n",
        "\n",
        "The training process typically takes about 10 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_uZW-IHqOXh",
        "outputId": "747a0536-fc1b-4943-ac51-83937ecea83e"
      },
      "source": [
        "model.fit(train_images, train_coords, epochs=50, validation_data=(val_images, val_coords), callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 560s 11s/step - loss: 108222.3281 - mae: 266.1209 - val_loss: 26522.7500 - val_mae: 136.7815\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 572s 11s/step - loss: 29379.6504 - mae: 144.4532 - val_loss: 27375.0859 - val_mae: 137.6016\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 556s 11s/step - loss: 29954.3574 - mae: 146.2423 - val_loss: 27161.7891 - val_mae: 137.6033\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 556s 11s/step - loss: 32339.1934 - mae: 148.8018 - val_loss: 31197.0918 - val_mae: 144.6190\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 557s 11s/step - loss: 30449.5547 - mae: 145.9675 - val_loss: 26523.2031 - val_mae: 136.9295\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 572s 11s/step - loss: 29622.0391 - mae: 144.3887 - val_loss: 26391.2500 - val_mae: 136.5642\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 570s 11s/step - loss: 29554.5645 - mae: 143.4848 - val_loss: 26205.8730 - val_mae: 136.0858\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 554s 11s/step - loss: 29146.9082 - mae: 141.8564 - val_loss: 31867.4258 - val_mae: 149.3179\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 555s 11s/step - loss: 21661.7324 - mae: 113.6631 - val_loss: 10050.4717 - val_mae: 77.3582\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 556s 11s/step - loss: 7179.8862 - mae: 62.5804 - val_loss: 5120.4526 - val_mae: 52.5338\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 571s 11s/step - loss: 4110.9956 - mae: 47.8075 - val_loss: 3813.7200 - val_mae: 46.5016\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 571s 11s/step - loss: 3455.5398 - mae: 44.6675 - val_loss: 4044.3572 - val_mae: 48.8161\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 570s 11s/step - loss: 3152.9595 - mae: 42.7239 - val_loss: 3446.1816 - val_mae: 44.8332\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 581s 12s/step - loss: 2783.2612 - mae: 39.9612 - val_loss: 3157.7935 - val_mae: 42.7928\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 573s 11s/step - loss: 2644.4929 - mae: 38.9631 - val_loss: 3515.7234 - val_mae: 46.2191\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 557s 11s/step - loss: 3078.8540 - mae: 42.1744 - val_loss: 4377.8081 - val_mae: 49.4533\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 575s 12s/step - loss: 3093.3948 - mae: 42.7625 - val_loss: 3358.7688 - val_mae: 42.9289\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - ETA: 0s - loss: 2632.7576 - mae: 39.0431 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZanoeIQWsoa"
      },
      "source": [
        "##Evaluate the training process\n",
        "\n",
        "Tensorflow has a useful tool called ```Tensorboard``` that helps evaluating the training process based on the saved log files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoomIOKSjQw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "outputId": "2501d5dd-dad4-4d5c-b930-e4d1052156b1"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 1070), started 3:47:44 ago. (Use '!kill 1070' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PTgATpV7cbk"
      },
      "source": [
        "Let's check if our model can predict "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "r3Ur2nRY0g1h",
        "outputId": "281a931b-d394-4803-f5c0-53c733a492a9"
      },
      "source": [
        "model.predict(images[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6d0add1481e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YWDrHsm768Q"
      },
      "source": [
        "Seemingly it shows some signs of life, however that list of coordinates is not that easy to evaluate. Let's create a more meaningful representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3PeJPd8gmb-5",
        "outputId": "25b39ba2-52e6-4f05-a635-9177445b4614"
      },
      "source": [
        "def show_example_set(start_from=0):\n",
        "  print('+ ground truth\\nx prediction')\n",
        "  pad_size = 100\n",
        "  plt.figure(figsize=(20,15))\n",
        "  for i in range(20):\n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    prediction = model.predict(images[0][0])\n",
        "    img = images[start_from+i]\n",
        "    c = 64\n",
        "    img = np.pad(img, pad_width=[(pad_size,pad_size), (pad_size,pad_size), (0,0)], \n",
        "                 mode='constant', constant_values=[(c,c),(c,c),(c,c)])\n",
        "    plt.imshow(img)\n",
        "    new_pos = coords[start_from+i] + pad_size\n",
        "    start_pos = coords_start[start_from+i] + pad_size\n",
        "    plt.plot(new_pos[0], new_pos[1], 'w+')\n",
        "    plt.plot(prediction[0,0], prediction[0,1], 'yx')\n",
        "    plt.xlabel(f'{start_from+i}: {accuracy(start_pos, new_pos, prediction):.0f}%').set_color(\"white\")\n",
        "  plt.show()\n",
        "\n",
        "def accuracy(start_pos, new_pos, prediction):\n",
        "    return max(0, (1 - np.linalg.norm(prediction - new_pos) / np.linalg.norm(start_pos - new_pos))) * 100\n",
        "\n",
        "show_example_set(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+ ground truth\n",
            "x prediction\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 768, 768, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 768, 768, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (32, 3).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-da5da97d73f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_pos\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mshow_example_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-da5da97d73f4>\u001b[0m in \u001b[0;36mshow_example_set\u001b[0;34m(start_from)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_from\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3460\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3382\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:369 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:415 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/layers/preprocessing/image_preprocessing.py:102 call\n        method=self._interpolation_method)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/image_ops_impl.py:1723 resize_images_v2\n        skip_resize_if_same=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/image_ops_impl.py:1396 _resize_images_common\n        raise ValueError('\\'images\\' must have either 3 or 4 dimensions.')\n\n    ValueError: 'images' must have either 3 or 4 dimensions.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANIAAADDCAYAAAD3E098AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAACfklEQVR4nO3WwU0DUQxAwf2IEjZntv9akiJyhh5MA0Ei4kUENHO1D748yWtmNuBnXn77APgPhAQBIUFASBAQEgSEBIHXe5b3fZ/jOB50Cjy3y+XyMTOnW7O7QjqOYzufz81V8Mesta5fzbx2EBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhAQBIUFASBAQEgSEBAEhQUBIEBASBIQEASFBQEgQEBIEhASBNTPfX17rfdu26+POgaf2NjOnW4O7QgJu89pBQEgQEBIEhAQBIUFASBAQEgSEBAEhQeATj4YbJ34EICUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x1080 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ic1iucRNOjF"
      },
      "source": [
        "Let's check the overall accuracy of our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKFNirKujzaT",
        "outputId": "48b38123-230f-442d-86ff-88c585b22841"
      },
      "source": [
        "print(f'Overall accuracy: {accuracy(coords_start, coords, model.predict(images)):.0f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy: 65%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X8Bfo_rMnWg"
      },
      "source": [
        "#Save the trained model\n",
        "\n",
        "Finally save and convert our model to the Tensorflow lite format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAdrBQl_m2tz"
      },
      "source": [
        "model_name = 'truss_game_AI_model'\n",
        "model.save(model_name)\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(model_name)\n",
        "tflite_model = converter.convert()\n",
        "with open('/content/' + model_name + '.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGAjzN5WNGKT"
      },
      "source": [
        "To use the model in the game, all you need to do is to download the tflite model file and overwrite the existing one in your local code repo.\n",
        "\n",
        "Have fun experimenting!"
      ]
    }
  ]
}